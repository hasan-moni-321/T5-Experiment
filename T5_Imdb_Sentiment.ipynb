{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41snJs85wR7I"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==2.9.0 \n",
    "!pip install pytorch_lightning==0.7.5\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjxwRtKv_22h",
    "outputId": "b8047187-5fb9-4589-c7b0-bc893cb8e7c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os, re, random, logging, argparse, glob, time\n",
    "\n",
    "from itertools import chain \n",
    "from string import punctuation \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "OcDVveF1GoLw"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3B8vZCS2HzE7"
   },
   "source": [
    "# T5 Fine Tuner Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "3wW4S70oGoOm"
   },
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "  def __init__(self, hparams):\n",
    "    super(T5FineTuner, self).__init__()\n",
    "    self.hparams = hparams\n",
    "    \n",
    "    self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
    "    self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
    "  \n",
    "  def is_logger(self):\n",
    "    return self.trainer.proc_rank <= 0\n",
    "  \n",
    "  def forward(\n",
    "      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
    "  ):\n",
    "    return self.model(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        decoder_input_ids=decoder_input_ids,\n",
    "        decoder_attention_mask=decoder_attention_mask,\n",
    "        lm_labels=lm_labels,\n",
    "    )\n",
    "\n",
    "  def _step(self, batch):\n",
    "    lm_labels = batch[\"target_ids\"]\n",
    "    lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "    outputs = self(\n",
    "        input_ids=batch[\"source_ids\"],\n",
    "        attention_mask=batch[\"source_mask\"],\n",
    "        lm_labels=lm_labels,\n",
    "        decoder_attention_mask=batch['target_mask']\n",
    "    )\n",
    "\n",
    "    loss = outputs[0]\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    loss = self._step(batch)\n",
    "\n",
    "    tensorboard_logs = {\"train_loss\": loss}\n",
    "    return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "  \n",
    "  def training_epoch_end(self, outputs):\n",
    "    avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "    tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "    return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    loss = self._step(batch)\n",
    "    return {\"val_loss\": loss}\n",
    "  \n",
    "  def validation_epoch_end(self, outputs):\n",
    "    avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "    tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "    return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "    model = self.model\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": self.hparams.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "    self.opt = optimizer\n",
    "    return [optimizer]\n",
    "  \n",
    "  def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n",
    "    if self.trainer.use_tpu:\n",
    "      xm.optimizer_step(optimizer)\n",
    "    else:\n",
    "      optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    self.lr_scheduler.step()\n",
    "  \n",
    "  def get_tqdm_dict(self):\n",
    "    tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "    return tqdm_dict\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparams)\n",
    "    dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=4)\n",
    "    t_total = (\n",
    "        (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
    "        // self.hparams.gradient_accumulation_steps\n",
    "        * float(self.hparams.num_train_epochs)\n",
    "    )\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "    self.lr_scheduler = scheduler\n",
    "    return dataloader\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"val\", args=self.hparams)\n",
    "    return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "8KK6f5U0GoRO"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "  def on_validation_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Validation results *****\")\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "      # Log results\n",
    "      for key in sorted(metrics):\n",
    "        if key not in [\"log\", \"progress_bar\"]:\n",
    "          logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "  def on_test_end(self, trainer, pl_module):\n",
    "    logger.info(\"***** Test results *****\")\n",
    "\n",
    "    if pl_module.is_logger():\n",
    "      metrics = trainer.callback_metrics\n",
    "\n",
    "      # Log and save results to file\n",
    "      output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
    "      with open(output_test_results_file, \"w\") as writer:\n",
    "        for key in sorted(metrics):\n",
    "          if key not in [\"log\", \"progress_bar\"]:\n",
    "            logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "            writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqkZmKuuIJWs"
   },
   "source": [
    "# HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4nUO0ypKGoUH"
   },
   "outputs": [],
   "source": [
    "args_dict = dict(\n",
    "    data_dir=\"\", # path for data files\n",
    "    output_dir=\"\", # path to save the checkpoints\n",
    "    model_name_or_path='t5-base',\n",
    "    tokenizer_name_or_path='t5-base',\n",
    "    max_seq_length=512,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=8,\n",
    "    eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    gradient_accumulation_steps=16,\n",
    "    n_gpu=1,\n",
    "    early_stop_callback=False,\n",
    "    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmGf1DE8Ax0g",
    "outputId": "657d3438-3d20-47d9-b0bb-371f0e305677"
   },
   "outputs": [],
   "source": [
    "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xvf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "uIVsg0lrAx38"
   },
   "outputs": [],
   "source": [
    "train_pos_files = glob.glob('aclImdb/train/pos/*.txt')\n",
    "train_neg_files = glob.glob('aclImdb/train/neg/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kdm1rZ9WIq93",
    "outputId": "423cf7f6-91c1-4bec-a7d6-fa87ff5e09d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500)"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pos_files), len(train_neg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "-OnXPnStIrBB"
   },
   "outputs": [],
   "source": [
    "!mkdir aclImdb/val aclImdb/val/pos aclImdb/val/neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "BbXfF0TvIrDn"
   },
   "outputs": [],
   "source": [
    "random.shuffle(train_pos_files)\n",
    "random.shuffle(train_neg_files)\n",
    "\n",
    "val_pos_files = train_pos_files[:1000]\n",
    "val_neg_files = train_neg_files[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "b630Sy4GIrFw"
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "1NHw7VH-IrIN"
   },
   "outputs": [],
   "source": [
    "for f in val_pos_files:\n",
    "  shutil.move(f,  'aclImdb/val/pos')\n",
    "for f in val_neg_files:\n",
    "  shutil.move(f,  'aclImdb/val/neg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pK5PlKyI0hd"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "akt13bOeIrKS",
    "outputId": "5fb675eb-3b0e-43c4-b1ee-0d404fe13bbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZ8tUGGpI3cP",
    "outputId": "1bd954ab-b1f3-491e-c5f4-2717445255cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_neg = tokenizer.encode('negative </s>')\n",
    "ids_pos = tokenizer.encode('positive </s>')\n",
    "len(ids_neg), len(ids_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "bjvnkIPZI3e5"
   },
   "outputs": [],
   "source": [
    "class ImdbDataset(Dataset):\n",
    "  def __init__(self, tokenizer, data_dir, type_path,  max_len=512):\n",
    "    self.pos_file_path = os.path.join(data_dir, type_path, 'pos')\n",
    "    self.neg_file_path = os.path.join(data_dir, type_path, 'neg')\n",
    "    \n",
    "    self.pos_files = glob.glob(\"%s/*.txt\" % self.pos_file_path)\n",
    "    self.neg_files = glob.glob(\"%s/*.txt\" % self.neg_file_path)\n",
    "    \n",
    "    self.max_len = max_len\n",
    "    self.tokenizer = tokenizer\n",
    "    self.inputs = []\n",
    "    self.targets = []\n",
    "\n",
    "    self._build()\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.inputs)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "    target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "\n",
    "    src_mask    = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "    target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "\n",
    "    return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "  \n",
    "  def _build(self):\n",
    "    self._buil_examples_from_files(self.pos_files, 'positive')\n",
    "    self._buil_examples_from_files(self.neg_files, 'negative')\n",
    "  \n",
    "  def _buil_examples_from_files(self, files, sentiment):\n",
    "    REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "    REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "    for path in files:\n",
    "      with open(path, 'r') as f:\n",
    "        text = f.read()\n",
    "      \n",
    "      line = text.strip()\n",
    "      line = REPLACE_NO_SPACE.sub(\"\", line) \n",
    "      line = REPLACE_WITH_SPACE.sub(\"\", line)\n",
    "      line = line + ' </s>'\n",
    "\n",
    "      target = sentiment + \" </s>\"\n",
    "\n",
    "       # tokenize inputs\n",
    "      tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "          [line], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n",
    "      )\n",
    "       # tokenize targets\n",
    "      tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "          [target], max_length=2, pad_to_max_length=True, return_tensors=\"pt\"\n",
    "      )\n",
    "\n",
    "      self.inputs.append(tokenized_inputs)\n",
    "      self.targets.append(tokenized_targets)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voei1EPEI3iA",
    "outputId": "27ceab4a-b221-40ac-97a1-48b966ddf367"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ImdbDataset(tokenizer, 'aclImdb', 'val',  max_len=512)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Axo3H0-6IrMn",
    "outputId": "cb1d43f7-2981-4409-bab2-99812089b82f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is superb the acting wonderful sets clothes music but most of all the story itselfI am amazed there arent more reviews of this movie certainly one of the best of the 1980sIts also a wonderful movie to see in tandem with the great Random Harvest which has much the same opening crisis a middle aged unknown English WWI officer is in a hospital toward the close of the war suffering from shell shock and complete amnesia without any idea of his name origin or anywhere he belongs he proves to be a very wealthy established man when he recovers he will not remember the years before the war But there the movies resemblances endMy warmest thanks to all who participated in the movie particularly the actors Ian Holm Alan Bates Ann Margret what a great and surprising casting choice Glenda Jackson Julie ChristieThis one stays with you forever\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "data = dataset[28]\n",
    "print(tokenizer.decode(data['source_ids']))\n",
    "print(tokenizer.decode(data['target_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "H7MXYi0gJBeo"
   },
   "outputs": [],
   "source": [
    "!mkdir -p t5_imdb_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "islW8hmPJBh8"
   },
   "outputs": [],
   "source": [
    "args_dict.update({'data_dir': 'aclImdb', 'output_dir': 't5_imdb_sentiment', 'num_train_epochs':2})\n",
    "args = argparse.Namespace(**args_dict)\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    early_stop_callback=False,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[LoggingCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "qI9MmUQ5JBk1"
   },
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, args):\n",
    "  return ImdbDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "IfKwrSSqJIy3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVUmxm5iJJ76"
   },
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "818a22c2de8643d6ba2d7280fc29ec92",
      "2a7912bca01f4b8899c1f8a720fcb8ad",
      "fb774c80a71c40f6923477ff6f00fef6",
      "bb4052d977284705983851c44cd1bfba",
      "aebd30288b4044bab1b1a0f9f3a329bd",
      "0e6b30da2d81465c8a5031cdfb9d34c1",
      "d2bd31657157479daaaa7a7540a5a509",
      "14e3380b02234c57bcf28113d4465301",
      "3f0788856a524f0ea846eedf2395cd14",
      "cd8ef8b38c994a1999462f9223207d37",
      "e26037505d8b4000a6dd7201e30c92d0",
      "828b17739bc347f2b3f17c302fe29ecd",
      "3733bf628ccb4901aaedeab4633bad2c",
      "f21d8dc9aa524e7f8a1c1191580ec695",
      "3a6e988601574b95b4e4ba3f7d186fb4",
      "f3d2f77978e94d468361da7056e4555c"
     ]
    },
    "id": "zY_ZNCksJI16",
    "outputId": "a175cb92-92dc-4de3-cdde-23b2130fc2cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140240659582544 acquired on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n",
      "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp36tvr5nm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818a22c2de8643d6ba2d7280fc29ec92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.file_utils:storing https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json in cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n",
      "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n",
      "INFO:filelock:Lock 140240659582544 released on /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b.lock\n",
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/t5-base-config.json from cache at /root/.cache/torch/transformers/40578967d1f029acb6162b36db9d8b4307063e885990ccd297c2c5be1cf1b3d7.2995d650f5eba18c8baa4146e210d32d56165e90d374281741fc78b872cd6c9b\n",
      "INFO:transformers.configuration_utils:Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:filelock:Lock 140240609682128 acquired on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n",
      "INFO:transformers.file_utils:https://cdn.huggingface.co/t5-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp_dqycin4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0788856a524f0ea846eedf2395cd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.file_utils:storing https://cdn.huggingface.co/t5-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n",
      "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n",
      "INFO:filelock:Lock 140240609682128 released on /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa.lock\n",
      "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/t5-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/f6f2fde9fa7611f4eff74620de9cbe734e7a717b5b143bd283cae4c2d6022990.54f906ff53bd09195cfc183a29cadc81b7705f07fcdb796d24163cb632b6bdfa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_utils:Weights of T5ForConditionalGeneration not initialized from pretrained model: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/t5-spiece.model from cache at /root/.cache/torch/transformers/68f1b8dbca4350743bb54b8c4169fd38cbabaad564f85a9239337a8d0342af9f.9995af32582a1a7062cb3173c118cb7b4636fa03feb967340f20fc37406f021f\n"
     ]
    }
   ],
   "source": [
    "model = T5FineTuner(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JK-EgT8JObm"
   },
   "source": [
    "# Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epFU7T1oJI4Z",
    "outputId": "fffb3be1-d7f3-4908-9efd-a27db4ce2120"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**train_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "723194ef36e84be7bbdad7ef612db7f6",
      "4324eea8cd4c4cfca445a502ad780ae5",
      "e9bb4717bbc54bc78e3f865295954524",
      "4d847cae27924548b542c8cd027e8743",
      "30def0feafdf4fb0b0608654816a6cc6",
      "bd7c7b15af4640389d03a461e59ed67a",
      "5c4c75c93ef34f899b89543893de421c",
      "5c8899aec2144c0f85595ba30adb8cff",
      "4deb8e18764d449d925323457e999855",
      "cc0658a972514176a114d30390d97979",
      "cf47153db36941278f55f270eade36f0",
      "119733b98e0c4cb6a22aa97143e35b09",
      "49096c116ac74c2cabe7279b93671618",
      "319c8bcbd5934059860c677f7ed24aad",
      "f4d302e039704a2ab2c35b61a90ceb24",
      "af371d5453b743558cbccf3c250743c9",
      "9cad5d60d32a4689b754626a50ef2fb0",
      "a7c85a38e3504f42859620d583c80025",
      "744a6288f3af4526924d50ea99334796",
      "f3964ccfda154661810feca1129a2f87",
      "15368d6fee634355b25bdda23c385b6f",
      "d7f4620330cf4affac01d9b480128ae0",
      "35d72f1a32ae4c5ebe1b237bd9880099",
      "7a4eaa255b0144dba417dcf5be147274",
      "6747d086529349158632278e67b2eda5",
      "c1a9c72c12b2451ab400a7aba3b25135",
      "59d70863485248b6b6e6bfd9c7312255",
      "e3ad19060d6e48528fbf91568e4e20b5",
      "41db090906044995bab2cc114e8df429",
      "1b317b6e12a544d09a5e511989213ae8",
      "8532abe29c7f46e0b157ae58089849bb",
      "2ceb41206ac34659b679cd69479097f2"
     ]
    },
    "id": "uPJxm9JfJI6h",
    "outputId": "54e39db6-bec5-4bfa-8f97-11c1d1cb8f88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "    | Name                                                                  | Type                       | Params\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                                 | T5ForConditionalGeneration | 222 M \n",
      "1   | model.shared                                                          | Embedding                  | 24 M  \n",
      "2   | model.encoder                                                         | T5Stack                    | 109 M \n",
      "3   | model.encoder.block                                                   | ModuleList                 | 84 M  \n",
      "4   | model.encoder.block.0                                                 | T5Block                    | 7 M   \n",
      "5   | model.encoder.block.0.layer                                           | ModuleList                 | 7 M   \n",
      "6   | model.encoder.block.0.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "7   | model.encoder.block.0.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "8   | model.encoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "9   | model.encoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "10  | model.encoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "11  | model.encoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "12  | model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 384   \n",
      "13  | model.encoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "14  | model.encoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
      "15  | model.encoder.block.0.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "16  | model.encoder.block.0.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "17  | model.encoder.block.0.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "18  | model.encoder.block.0.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "19  | model.encoder.block.0.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "20  | model.encoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "21  | model.encoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
      "22  | model.encoder.block.1                                                 | T5Block                    | 7 M   \n",
      "23  | model.encoder.block.1.layer                                           | ModuleList                 | 7 M   \n",
      "24  | model.encoder.block.1.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "25  | model.encoder.block.1.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "26  | model.encoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "27  | model.encoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "28  | model.encoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "29  | model.encoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "30  | model.encoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "31  | model.encoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
      "32  | model.encoder.block.1.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "33  | model.encoder.block.1.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "34  | model.encoder.block.1.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "35  | model.encoder.block.1.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "36  | model.encoder.block.1.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "37  | model.encoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "38  | model.encoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
      "39  | model.encoder.block.2                                                 | T5Block                    | 7 M   \n",
      "40  | model.encoder.block.2.layer                                           | ModuleList                 | 7 M   \n",
      "41  | model.encoder.block.2.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "42  | model.encoder.block.2.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "43  | model.encoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "44  | model.encoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "45  | model.encoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "46  | model.encoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "47  | model.encoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "48  | model.encoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
      "49  | model.encoder.block.2.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "50  | model.encoder.block.2.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "51  | model.encoder.block.2.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "52  | model.encoder.block.2.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "53  | model.encoder.block.2.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "54  | model.encoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "55  | model.encoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
      "56  | model.encoder.block.3                                                 | T5Block                    | 7 M   \n",
      "57  | model.encoder.block.3.layer                                           | ModuleList                 | 7 M   \n",
      "58  | model.encoder.block.3.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "59  | model.encoder.block.3.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "60  | model.encoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "61  | model.encoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "62  | model.encoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "63  | model.encoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "64  | model.encoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "65  | model.encoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
      "66  | model.encoder.block.3.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "67  | model.encoder.block.3.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "68  | model.encoder.block.3.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "69  | model.encoder.block.3.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "70  | model.encoder.block.3.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "71  | model.encoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "72  | model.encoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
      "73  | model.encoder.block.4                                                 | T5Block                    | 7 M   \n",
      "74  | model.encoder.block.4.layer                                           | ModuleList                 | 7 M   \n",
      "75  | model.encoder.block.4.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "76  | model.encoder.block.4.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "77  | model.encoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "78  | model.encoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "79  | model.encoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "80  | model.encoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "81  | model.encoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "82  | model.encoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
      "83  | model.encoder.block.4.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "84  | model.encoder.block.4.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "85  | model.encoder.block.4.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "86  | model.encoder.block.4.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "87  | model.encoder.block.4.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "88  | model.encoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "89  | model.encoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
      "90  | model.encoder.block.5                                                 | T5Block                    | 7 M   \n",
      "91  | model.encoder.block.5.layer                                           | ModuleList                 | 7 M   \n",
      "92  | model.encoder.block.5.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "93  | model.encoder.block.5.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "94  | model.encoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "95  | model.encoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "96  | model.encoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "97  | model.encoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "98  | model.encoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "99  | model.encoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
      "100 | model.encoder.block.5.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "101 | model.encoder.block.5.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "102 | model.encoder.block.5.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "103 | model.encoder.block.5.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "104 | model.encoder.block.5.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "105 | model.encoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "106 | model.encoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
      "107 | model.encoder.block.6                                                 | T5Block                    | 7 M   \n",
      "108 | model.encoder.block.6.layer                                           | ModuleList                 | 7 M   \n",
      "109 | model.encoder.block.6.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "110 | model.encoder.block.6.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "111 | model.encoder.block.6.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "112 | model.encoder.block.6.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "113 | model.encoder.block.6.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "114 | model.encoder.block.6.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "115 | model.encoder.block.6.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "116 | model.encoder.block.6.layer.0.dropout                                 | Dropout                    | 0     \n",
      "117 | model.encoder.block.6.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "118 | model.encoder.block.6.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "119 | model.encoder.block.6.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "120 | model.encoder.block.6.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "121 | model.encoder.block.6.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "122 | model.encoder.block.6.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "123 | model.encoder.block.6.layer.1.dropout                                 | Dropout                    | 0     \n",
      "124 | model.encoder.block.7                                                 | T5Block                    | 7 M   \n",
      "125 | model.encoder.block.7.layer                                           | ModuleList                 | 7 M   \n",
      "126 | model.encoder.block.7.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "127 | model.encoder.block.7.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "128 | model.encoder.block.7.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "129 | model.encoder.block.7.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "130 | model.encoder.block.7.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "131 | model.encoder.block.7.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "132 | model.encoder.block.7.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "133 | model.encoder.block.7.layer.0.dropout                                 | Dropout                    | 0     \n",
      "134 | model.encoder.block.7.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "135 | model.encoder.block.7.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "136 | model.encoder.block.7.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "137 | model.encoder.block.7.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "138 | model.encoder.block.7.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "139 | model.encoder.block.7.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "140 | model.encoder.block.7.layer.1.dropout                                 | Dropout                    | 0     \n",
      "141 | model.encoder.block.8                                                 | T5Block                    | 7 M   \n",
      "142 | model.encoder.block.8.layer                                           | ModuleList                 | 7 M   \n",
      "143 | model.encoder.block.8.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "144 | model.encoder.block.8.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "145 | model.encoder.block.8.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "146 | model.encoder.block.8.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "147 | model.encoder.block.8.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "148 | model.encoder.block.8.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "149 | model.encoder.block.8.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "150 | model.encoder.block.8.layer.0.dropout                                 | Dropout                    | 0     \n",
      "151 | model.encoder.block.8.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "152 | model.encoder.block.8.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "153 | model.encoder.block.8.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "154 | model.encoder.block.8.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "155 | model.encoder.block.8.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "156 | model.encoder.block.8.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "157 | model.encoder.block.8.layer.1.dropout                                 | Dropout                    | 0     \n",
      "158 | model.encoder.block.9                                                 | T5Block                    | 7 M   \n",
      "159 | model.encoder.block.9.layer                                           | ModuleList                 | 7 M   \n",
      "160 | model.encoder.block.9.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "161 | model.encoder.block.9.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "162 | model.encoder.block.9.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "163 | model.encoder.block.9.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "164 | model.encoder.block.9.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "165 | model.encoder.block.9.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "166 | model.encoder.block.9.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "167 | model.encoder.block.9.layer.0.dropout                                 | Dropout                    | 0     \n",
      "168 | model.encoder.block.9.layer.1                                         | T5LayerFF                  | 4 M   \n",
      "169 | model.encoder.block.9.layer.1.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "170 | model.encoder.block.9.layer.1.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "171 | model.encoder.block.9.layer.1.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "172 | model.encoder.block.9.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "173 | model.encoder.block.9.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "174 | model.encoder.block.9.layer.1.dropout                                 | Dropout                    | 0     \n",
      "175 | model.encoder.block.10                                                | T5Block                    | 7 M   \n",
      "176 | model.encoder.block.10.layer                                          | ModuleList                 | 7 M   \n",
      "177 | model.encoder.block.10.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
      "178 | model.encoder.block.10.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
      "179 | model.encoder.block.10.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
      "180 | model.encoder.block.10.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
      "181 | model.encoder.block.10.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
      "182 | model.encoder.block.10.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
      "183 | model.encoder.block.10.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
      "184 | model.encoder.block.10.layer.0.dropout                                | Dropout                    | 0     \n",
      "185 | model.encoder.block.10.layer.1                                        | T5LayerFF                  | 4 M   \n",
      "186 | model.encoder.block.10.layer.1.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
      "187 | model.encoder.block.10.layer.1.DenseReluDense.wi                      | Linear                     | 2 M   \n",
      "188 | model.encoder.block.10.layer.1.DenseReluDense.wo                      | Linear                     | 2 M   \n",
      "189 | model.encoder.block.10.layer.1.DenseReluDense.dropout                 | Dropout                    | 0     \n",
      "190 | model.encoder.block.10.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
      "191 | model.encoder.block.10.layer.1.dropout                                | Dropout                    | 0     \n",
      "192 | model.encoder.block.11                                                | T5Block                    | 7 M   \n",
      "193 | model.encoder.block.11.layer                                          | ModuleList                 | 7 M   \n",
      "194 | model.encoder.block.11.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
      "195 | model.encoder.block.11.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
      "196 | model.encoder.block.11.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
      "197 | model.encoder.block.11.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
      "198 | model.encoder.block.11.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
      "199 | model.encoder.block.11.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
      "200 | model.encoder.block.11.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
      "201 | model.encoder.block.11.layer.0.dropout                                | Dropout                    | 0     \n",
      "202 | model.encoder.block.11.layer.1                                        | T5LayerFF                  | 4 M   \n",
      "203 | model.encoder.block.11.layer.1.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
      "204 | model.encoder.block.11.layer.1.DenseReluDense.wi                      | Linear                     | 2 M   \n",
      "205 | model.encoder.block.11.layer.1.DenseReluDense.wo                      | Linear                     | 2 M   \n",
      "206 | model.encoder.block.11.layer.1.DenseReluDense.dropout                 | Dropout                    | 0     \n",
      "207 | model.encoder.block.11.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
      "208 | model.encoder.block.11.layer.1.dropout                                | Dropout                    | 0     \n",
      "209 | model.encoder.final_layer_norm                                        | T5LayerNorm                | 768   \n",
      "210 | model.encoder.dropout                                                 | Dropout                    | 0     \n",
      "211 | model.decoder                                                         | T5Stack                    | 137 M \n",
      "212 | model.decoder.block                                                   | ModuleList                 | 113 M \n",
      "213 | model.decoder.block.0                                                 | T5Block                    | 9 M   \n",
      "214 | model.decoder.block.0.layer                                           | ModuleList                 | 9 M   \n",
      "215 | model.decoder.block.0.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "216 | model.decoder.block.0.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "217 | model.decoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "218 | model.decoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "219 | model.decoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "220 | model.decoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "221 | model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 384   \n",
      "222 | model.decoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "223 | model.decoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
      "224 | model.decoder.block.0.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "225 | model.decoder.block.0.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "226 | model.decoder.block.0.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "227 | model.decoder.block.0.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "228 | model.decoder.block.0.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "229 | model.decoder.block.0.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "230 | model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias | Embedding                  | 384   \n",
      "231 | model.decoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "232 | model.decoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
      "233 | model.decoder.block.0.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "234 | model.decoder.block.0.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "235 | model.decoder.block.0.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "236 | model.decoder.block.0.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "237 | model.decoder.block.0.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "238 | model.decoder.block.0.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "239 | model.decoder.block.0.layer.2.dropout                                 | Dropout                    | 0     \n",
      "240 | model.decoder.block.1                                                 | T5Block                    | 9 M   \n",
      "241 | model.decoder.block.1.layer                                           | ModuleList                 | 9 M   \n",
      "242 | model.decoder.block.1.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "243 | model.decoder.block.1.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "244 | model.decoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "245 | model.decoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "246 | model.decoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "247 | model.decoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "248 | model.decoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "249 | model.decoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
      "250 | model.decoder.block.1.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "251 | model.decoder.block.1.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "252 | model.decoder.block.1.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "253 | model.decoder.block.1.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "254 | model.decoder.block.1.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "255 | model.decoder.block.1.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "256 | model.decoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "257 | model.decoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
      "258 | model.decoder.block.1.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "259 | model.decoder.block.1.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "260 | model.decoder.block.1.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "261 | model.decoder.block.1.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "262 | model.decoder.block.1.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "263 | model.decoder.block.1.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "264 | model.decoder.block.1.layer.2.dropout                                 | Dropout                    | 0     \n",
      "265 | model.decoder.block.2                                                 | T5Block                    | 9 M   \n",
      "266 | model.decoder.block.2.layer                                           | ModuleList                 | 9 M   \n",
      "267 | model.decoder.block.2.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "268 | model.decoder.block.2.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "269 | model.decoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "270 | model.decoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "271 | model.decoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "272 | model.decoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "273 | model.decoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "274 | model.decoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
      "275 | model.decoder.block.2.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "276 | model.decoder.block.2.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "277 | model.decoder.block.2.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "278 | model.decoder.block.2.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "279 | model.decoder.block.2.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "280 | model.decoder.block.2.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "281 | model.decoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "282 | model.decoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
      "283 | model.decoder.block.2.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "284 | model.decoder.block.2.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "285 | model.decoder.block.2.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "286 | model.decoder.block.2.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "287 | model.decoder.block.2.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "288 | model.decoder.block.2.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "289 | model.decoder.block.2.layer.2.dropout                                 | Dropout                    | 0     \n",
      "290 | model.decoder.block.3                                                 | T5Block                    | 9 M   \n",
      "291 | model.decoder.block.3.layer                                           | ModuleList                 | 9 M   \n",
      "292 | model.decoder.block.3.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "293 | model.decoder.block.3.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "294 | model.decoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "295 | model.decoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "296 | model.decoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "297 | model.decoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "298 | model.decoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "299 | model.decoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
      "300 | model.decoder.block.3.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "301 | model.decoder.block.3.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "302 | model.decoder.block.3.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "303 | model.decoder.block.3.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "304 | model.decoder.block.3.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "305 | model.decoder.block.3.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "306 | model.decoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "307 | model.decoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
      "308 | model.decoder.block.3.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "309 | model.decoder.block.3.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "310 | model.decoder.block.3.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "311 | model.decoder.block.3.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "312 | model.decoder.block.3.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "313 | model.decoder.block.3.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "314 | model.decoder.block.3.layer.2.dropout                                 | Dropout                    | 0     \n",
      "315 | model.decoder.block.4                                                 | T5Block                    | 9 M   \n",
      "316 | model.decoder.block.4.layer                                           | ModuleList                 | 9 M   \n",
      "317 | model.decoder.block.4.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "318 | model.decoder.block.4.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "319 | model.decoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "320 | model.decoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "321 | model.decoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "322 | model.decoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "323 | model.decoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "324 | model.decoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
      "325 | model.decoder.block.4.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "326 | model.decoder.block.4.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "327 | model.decoder.block.4.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "328 | model.decoder.block.4.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "329 | model.decoder.block.4.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "330 | model.decoder.block.4.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "331 | model.decoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "332 | model.decoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
      "333 | model.decoder.block.4.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "334 | model.decoder.block.4.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "335 | model.decoder.block.4.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "336 | model.decoder.block.4.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "337 | model.decoder.block.4.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "338 | model.decoder.block.4.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "339 | model.decoder.block.4.layer.2.dropout                                 | Dropout                    | 0     \n",
      "340 | model.decoder.block.5                                                 | T5Block                    | 9 M   \n",
      "341 | model.decoder.block.5.layer                                           | ModuleList                 | 9 M   \n",
      "342 | model.decoder.block.5.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "343 | model.decoder.block.5.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "344 | model.decoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "345 | model.decoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "346 | model.decoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "347 | model.decoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "348 | model.decoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "349 | model.decoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
      "350 | model.decoder.block.5.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "351 | model.decoder.block.5.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "352 | model.decoder.block.5.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "353 | model.decoder.block.5.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "354 | model.decoder.block.5.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "355 | model.decoder.block.5.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "356 | model.decoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "357 | model.decoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
      "358 | model.decoder.block.5.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "359 | model.decoder.block.5.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "360 | model.decoder.block.5.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "361 | model.decoder.block.5.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "362 | model.decoder.block.5.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "363 | model.decoder.block.5.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "364 | model.decoder.block.5.layer.2.dropout                                 | Dropout                    | 0     \n",
      "365 | model.decoder.block.6                                                 | T5Block                    | 9 M   \n",
      "366 | model.decoder.block.6.layer                                           | ModuleList                 | 9 M   \n",
      "367 | model.decoder.block.6.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "368 | model.decoder.block.6.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "369 | model.decoder.block.6.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "370 | model.decoder.block.6.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "371 | model.decoder.block.6.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "372 | model.decoder.block.6.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "373 | model.decoder.block.6.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "374 | model.decoder.block.6.layer.0.dropout                                 | Dropout                    | 0     \n",
      "375 | model.decoder.block.6.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "376 | model.decoder.block.6.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "377 | model.decoder.block.6.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "378 | model.decoder.block.6.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "379 | model.decoder.block.6.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "380 | model.decoder.block.6.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "381 | model.decoder.block.6.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "382 | model.decoder.block.6.layer.1.dropout                                 | Dropout                    | 0     \n",
      "383 | model.decoder.block.6.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "384 | model.decoder.block.6.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "385 | model.decoder.block.6.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "386 | model.decoder.block.6.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "387 | model.decoder.block.6.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "388 | model.decoder.block.6.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "389 | model.decoder.block.6.layer.2.dropout                                 | Dropout                    | 0     \n",
      "390 | model.decoder.block.7                                                 | T5Block                    | 9 M   \n",
      "391 | model.decoder.block.7.layer                                           | ModuleList                 | 9 M   \n",
      "392 | model.decoder.block.7.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "393 | model.decoder.block.7.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "394 | model.decoder.block.7.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "395 | model.decoder.block.7.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "396 | model.decoder.block.7.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "397 | model.decoder.block.7.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "398 | model.decoder.block.7.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "399 | model.decoder.block.7.layer.0.dropout                                 | Dropout                    | 0     \n",
      "400 | model.decoder.block.7.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "401 | model.decoder.block.7.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "402 | model.decoder.block.7.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "403 | model.decoder.block.7.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "404 | model.decoder.block.7.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "405 | model.decoder.block.7.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "406 | model.decoder.block.7.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "407 | model.decoder.block.7.layer.1.dropout                                 | Dropout                    | 0     \n",
      "408 | model.decoder.block.7.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "409 | model.decoder.block.7.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "410 | model.decoder.block.7.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "411 | model.decoder.block.7.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "412 | model.decoder.block.7.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "413 | model.decoder.block.7.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "414 | model.decoder.block.7.layer.2.dropout                                 | Dropout                    | 0     \n",
      "415 | model.decoder.block.8                                                 | T5Block                    | 9 M   \n",
      "416 | model.decoder.block.8.layer                                           | ModuleList                 | 9 M   \n",
      "417 | model.decoder.block.8.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "418 | model.decoder.block.8.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "419 | model.decoder.block.8.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "420 | model.decoder.block.8.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "421 | model.decoder.block.8.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "422 | model.decoder.block.8.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "423 | model.decoder.block.8.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "424 | model.decoder.block.8.layer.0.dropout                                 | Dropout                    | 0     \n",
      "425 | model.decoder.block.8.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "426 | model.decoder.block.8.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "427 | model.decoder.block.8.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "428 | model.decoder.block.8.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "429 | model.decoder.block.8.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "430 | model.decoder.block.8.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "431 | model.decoder.block.8.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "432 | model.decoder.block.8.layer.1.dropout                                 | Dropout                    | 0     \n",
      "433 | model.decoder.block.8.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "434 | model.decoder.block.8.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "435 | model.decoder.block.8.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "436 | model.decoder.block.8.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "437 | model.decoder.block.8.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "438 | model.decoder.block.8.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "439 | model.decoder.block.8.layer.2.dropout                                 | Dropout                    | 0     \n",
      "440 | model.decoder.block.9                                                 | T5Block                    | 9 M   \n",
      "441 | model.decoder.block.9.layer                                           | ModuleList                 | 9 M   \n",
      "442 | model.decoder.block.9.layer.0                                         | T5LayerSelfAttention       | 2 M   \n",
      "443 | model.decoder.block.9.layer.0.SelfAttention                           | T5Attention                | 2 M   \n",
      "444 | model.decoder.block.9.layer.0.SelfAttention.q                         | Linear                     | 589 K \n",
      "445 | model.decoder.block.9.layer.0.SelfAttention.k                         | Linear                     | 589 K \n",
      "446 | model.decoder.block.9.layer.0.SelfAttention.v                         | Linear                     | 589 K \n",
      "447 | model.decoder.block.9.layer.0.SelfAttention.o                         | Linear                     | 589 K \n",
      "448 | model.decoder.block.9.layer.0.layer_norm                              | T5LayerNorm                | 768   \n",
      "449 | model.decoder.block.9.layer.0.dropout                                 | Dropout                    | 0     \n",
      "450 | model.decoder.block.9.layer.1                                         | T5LayerCrossAttention      | 2 M   \n",
      "451 | model.decoder.block.9.layer.1.EncDecAttention                         | T5Attention                | 2 M   \n",
      "452 | model.decoder.block.9.layer.1.EncDecAttention.q                       | Linear                     | 589 K \n",
      "453 | model.decoder.block.9.layer.1.EncDecAttention.k                       | Linear                     | 589 K \n",
      "454 | model.decoder.block.9.layer.1.EncDecAttention.v                       | Linear                     | 589 K \n",
      "455 | model.decoder.block.9.layer.1.EncDecAttention.o                       | Linear                     | 589 K \n",
      "456 | model.decoder.block.9.layer.1.layer_norm                              | T5LayerNorm                | 768   \n",
      "457 | model.decoder.block.9.layer.1.dropout                                 | Dropout                    | 0     \n",
      "458 | model.decoder.block.9.layer.2                                         | T5LayerFF                  | 4 M   \n",
      "459 | model.decoder.block.9.layer.2.DenseReluDense                          | T5DenseReluDense           | 4 M   \n",
      "460 | model.decoder.block.9.layer.2.DenseReluDense.wi                       | Linear                     | 2 M   \n",
      "461 | model.decoder.block.9.layer.2.DenseReluDense.wo                       | Linear                     | 2 M   \n",
      "462 | model.decoder.block.9.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "463 | model.decoder.block.9.layer.2.layer_norm                              | T5LayerNorm                | 768   \n",
      "464 | model.decoder.block.9.layer.2.dropout                                 | Dropout                    | 0     \n",
      "465 | model.decoder.block.10                                                | T5Block                    | 9 M   \n",
      "466 | model.decoder.block.10.layer                                          | ModuleList                 | 9 M   \n",
      "467 | model.decoder.block.10.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
      "468 | model.decoder.block.10.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
      "469 | model.decoder.block.10.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
      "470 | model.decoder.block.10.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
      "471 | model.decoder.block.10.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
      "472 | model.decoder.block.10.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
      "473 | model.decoder.block.10.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
      "474 | model.decoder.block.10.layer.0.dropout                                | Dropout                    | 0     \n",
      "475 | model.decoder.block.10.layer.1                                        | T5LayerCrossAttention      | 2 M   \n",
      "476 | model.decoder.block.10.layer.1.EncDecAttention                        | T5Attention                | 2 M   \n",
      "477 | model.decoder.block.10.layer.1.EncDecAttention.q                      | Linear                     | 589 K \n",
      "478 | model.decoder.block.10.layer.1.EncDecAttention.k                      | Linear                     | 589 K \n",
      "479 | model.decoder.block.10.layer.1.EncDecAttention.v                      | Linear                     | 589 K \n",
      "480 | model.decoder.block.10.layer.1.EncDecAttention.o                      | Linear                     | 589 K \n",
      "481 | model.decoder.block.10.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
      "482 | model.decoder.block.10.layer.1.dropout                                | Dropout                    | 0     \n",
      "483 | model.decoder.block.10.layer.2                                        | T5LayerFF                  | 4 M   \n",
      "484 | model.decoder.block.10.layer.2.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
      "485 | model.decoder.block.10.layer.2.DenseReluDense.wi                      | Linear                     | 2 M   \n",
      "486 | model.decoder.block.10.layer.2.DenseReluDense.wo                      | Linear                     | 2 M   \n",
      "487 | model.decoder.block.10.layer.2.DenseReluDense.dropout                 | Dropout                    | 0     \n",
      "488 | model.decoder.block.10.layer.2.layer_norm                             | T5LayerNorm                | 768   \n",
      "489 | model.decoder.block.10.layer.2.dropout                                | Dropout                    | 0     \n",
      "490 | model.decoder.block.11                                                | T5Block                    | 9 M   \n",
      "491 | model.decoder.block.11.layer                                          | ModuleList                 | 9 M   \n",
      "492 | model.decoder.block.11.layer.0                                        | T5LayerSelfAttention       | 2 M   \n",
      "493 | model.decoder.block.11.layer.0.SelfAttention                          | T5Attention                | 2 M   \n",
      "494 | model.decoder.block.11.layer.0.SelfAttention.q                        | Linear                     | 589 K \n",
      "495 | model.decoder.block.11.layer.0.SelfAttention.k                        | Linear                     | 589 K \n",
      "496 | model.decoder.block.11.layer.0.SelfAttention.v                        | Linear                     | 589 K \n",
      "497 | model.decoder.block.11.layer.0.SelfAttention.o                        | Linear                     | 589 K \n",
      "498 | model.decoder.block.11.layer.0.layer_norm                             | T5LayerNorm                | 768   \n",
      "499 | model.decoder.block.11.layer.0.dropout                                | Dropout                    | 0     \n",
      "500 | model.decoder.block.11.layer.1                                        | T5LayerCrossAttention      | 2 M   \n",
      "501 | model.decoder.block.11.layer.1.EncDecAttention                        | T5Attention                | 2 M   \n",
      "502 | model.decoder.block.11.layer.1.EncDecAttention.q                      | Linear                     | 589 K \n",
      "503 | model.decoder.block.11.layer.1.EncDecAttention.k                      | Linear                     | 589 K \n",
      "504 | model.decoder.block.11.layer.1.EncDecAttention.v                      | Linear                     | 589 K \n",
      "505 | model.decoder.block.11.layer.1.EncDecAttention.o                      | Linear                     | 589 K \n",
      "506 | model.decoder.block.11.layer.1.layer_norm                             | T5LayerNorm                | 768   \n",
      "507 | model.decoder.block.11.layer.1.dropout                                | Dropout                    | 0     \n",
      "508 | model.decoder.block.11.layer.2                                        | T5LayerFF                  | 4 M   \n",
      "509 | model.decoder.block.11.layer.2.DenseReluDense                         | T5DenseReluDense           | 4 M   \n",
      "510 | model.decoder.block.11.layer.2.DenseReluDense.wi                      | Linear                     | 2 M   \n",
      "511 | model.decoder.block.11.layer.2.DenseReluDense.wo                      | Linear                     | 2 M   \n",
      "512 | model.decoder.block.11.layer.2.DenseReluDense.dropout                 | Dropout                    | 0     \n",
      "513 | model.decoder.block.11.layer.2.layer_norm                             | T5LayerNorm                | 768   \n",
      "514 | model.decoder.block.11.layer.2.dropout                                | Dropout                    | 0     \n",
      "515 | model.decoder.final_layer_norm                                        | T5LayerNorm                | 768   \n",
      "516 | model.decoder.dropout                                                 | Dropout                    | 0     \n",
      "517 | model.lm_head                                                         | Linear                     | 24 M  \n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723194ef36e84be7bbdad7ef612db7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4deb8e18764d449d925323457e999855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
      "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cad5d60d32a4689b754626a50ef2fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Validation results *****\n",
      "INFO:__main__:avg_val_loss = tensor(0.0790, device='cuda:0')\n",
      "\n",
      "INFO:__main__:loss = tensor(0.0176, device='cuda:0')\n",
      "\n",
      "INFO:__main__:train_loss = tensor(0.0176, device='cuda:0')\n",
      "\n",
      "INFO:__main__:val_loss = tensor(0.0790, device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6747d086529349158632278e67b2eda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:***** Validation results *****\n",
      "INFO:__main__:avg_train_loss = tensor(0.2916, device='cuda:0')\n",
      "\n",
      "INFO:__main__:avg_val_loss = tensor(0.0759, device='cuda:0')\n",
      "\n",
      "INFO:__main__:epoch = 0\n",
      "\n",
      "INFO:__main__:loss = tensor(0.0109, device='cuda:0')\n",
      "\n",
      "INFO:__main__:train_loss = tensor(0.0109, device='cuda:0')\n",
      "\n",
      "INFO:__main__:val_loss = tensor(0.0759, device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "NvoI9pRjJI9c"
   },
   "outputs": [],
   "source": [
    "!mkdir t5_base_imdb_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D1LZwIxdJI_l",
    "outputId": "4a9214fe-e179-46d8-95bf-f9e642db1ce4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:Configuration saved in t5_base_imdb_sentiment/config.json\n",
      "INFO:transformers.modeling_utils:Model weights saved in t5_base_imdb_sentiment/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "## save the model this way so next time you can load it using T5ForConditionalGeneration.from_pretrained\n",
    "model.model.save_pretrained('t5_base_imdb_sentiment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NGogo0YKeeA"
   },
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "RacnIJVGKboR"
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "d31Ho-TbKbrK"
   },
   "outputs": [],
   "source": [
    "dataset = ImdbDataset(tokenizer, 'aclImdb', 'test',  max_len=512)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "jHLWhdP_KbuR"
   },
   "outputs": [],
   "source": [
    "it = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sAgXSslrKbx6",
    "outputId": "0c23ec49-1d31-4392-f7c1-4d7de8865554"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(it)\n",
    "batch[\"source_ids\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "8CAzBgnuKwPh"
   },
   "outputs": [],
   "source": [
    "outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
    "                              attention_mask=batch['source_mask'].cuda(), \n",
    "                              max_length=2)\n",
    "\n",
    "dec = [tokenizer.decode(ids) for ids in outs]\n",
    "\n",
    "texts = [tokenizer.decode(ids) for ids in batch['source_ids']]\n",
    "targets = [tokenizer.decode(ids) for ids in batch['target_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A2BHJb9NKwSm",
    "outputId": "61f09fd7-83a3-426c-e050-0780b7cecc41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: God bless Randy Quaidhis leachorous Cousin Eddie in Vacation and Christmas Vacation\n",
      "hilariously stole the show He even made the awful Vegas Vacation at least worth a lookI will say\n",
      "that he tries hard in this made for TV sequel but that the script is so NON funny that the movie\n",
      "never really gets anywhere Quaid and the rest of the returning Vacation vets including the orginal\n",
      "Audrey Dana Barron are wasted here Even European Vacations Eric Idle cannot save the show in a brief\n",
      "cameoPathetic and sadactually painful to watchChristmas Vacation 2 is the worst of the Vacation\n",
      "franchise\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: This movie has one of the best club scenes very good soundtrack if you like technotrance\n",
      "musicsome situations As the main character Carl begins to take drugs for example are a little off\n",
      "reality but the plot is entertaining but the characters are all a little shallowId not recommend you\n",
      "to see this film if you dont like techno musicFor the plotacting alone this movie is a 410 with the\n",
      "really cool special effects and the club scenes and soundtrack its a 710 but if you would want to go\n",
      "to the movies just to hear nice tracks and grab a little club feeling its a 1010the special effects\n",
      "are sometimes hidden sometimes clearly visible ie fast moving cloudssunmoon morphing background\n",
      "morphing cutsI for one enjoyed it very much a shame there was no dancefloor in the cinema\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: I was pleasantly surprised to find this movie showing as a sneak preview in my local\n",
      "theaterWe have all seen this plot line before Top Gun GI Jane An Officer and a Gentleman but a good\n",
      "script still works This story is basically about the training of a Coast Guard rescue team with a\n",
      "couple of side story lines Kevin Costner plays a highly successful rescue team leader Ben Randall\n",
      "who is forced into heading the training team after a tough mission The movie takes us through the\n",
      "rigors of the training process and the personal stories of both the Costner character and that of\n",
      "Jake Fischer played by Ashton Kutcher I am happy to say that Ashton is great in this partThere are\n",
      "no great surprises in this movie and you will probably realize what is coming long before it arrives\n",
      "However the use of humor the exploration of the toughness of the training and the fun of watching\n",
      "Ben Randall do his own thing as a trainer kept me riveted and thoroughly entertained I really enjoy\n",
      "watching a movie that makes the entire audience laugh out loud gasp here and there and clap at the\n",
      "end as a tribute to the movieWe all had a good time despite a couple of tough moments in the\n",
      "movieand I think you will too\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: Most of Chaplins most famous films are his fulllength features And I assume most people have\n",
      "at most seen only a few clips of him from his prefeature days when he starred in dozens and dozens\n",
      "of comedy shorts This is really a shame as some wonderful shorts are pretty much waiting to be\n",
      "discovered by the world in the 21st centuryIf someone watches this film they have an excellent\n",
      "chance to see some of Chaplins better shorts because Chaplin himself chose these three shorts and\n",
      "strung them together with a bit of narration to make this 1959 feature film This is great for\n",
      "several reasons First in Chaplins earliest films from 19141915 his character of the Little Tramp is\n",
      "still in its earliest incarnations or is absent altogether Plus even when he is there he was often\n",
      "meanspirited and selfcenteredsomething very alien from the Little Tramp we have grown to love Second\n",
      "because the shorts that were chosen were in great condition if you watch this film you wont need to\n",
      "worry about watching scratchy film with gaps and lousy musical accompaniment that doesnt fit the\n",
      "action a common problemSo for a great look at Chaplins shorts at their finest give this film a\n",
      "chance Its sure to provide you some excellent laughs\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: i never made any comment here on IMDb but as i saw this movie i cant be quiet i just set up\n",
      "my account here only because this horrible movie in two words this movie is PURE CRAP the movie has\n",
      "no sense at all Nothing makes sense in this movie Watching this movie was pain all the way I dont\n",
      "understand why Val Kilmer agreed to do this movie He plays a minor role as a gang leader says few\n",
      "words and he is there like 5 minutes totalI bought this DVD based only because of Val Kilmer name on\n",
      "the box and the interesting pictures on the coverAs was stated in other review Moscow Zero stole my\n",
      "money and I want it back The title of the movie itself brought the clue about the rating everyone\n",
      "should give it ZERO\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Anatomie isnt very unique in horror genre in fact it isnt even scary at all It reminds me of\n",
      "its American cousins horror slashers Its just a copy of any other horror slasher and as a German\n",
      "movie its just too American with nothing to add to itActually Anatomie is too predictable and boring\n",
      "its plot is not intact and consistent Its got stupid scenes to it which dont even fit into a horror\n",
      "movie genre Amusing sex scenes with pop music and topless women in underwear Why do they need to\n",
      "have it all in just one movie They should have made a cheap German adult movie insteadI cant\n",
      "recommend this movie to anyone because its just too boring\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: If you go to the cinema to be entertained amused so as to fill up your time don't go out of\n",
      "your way to watch this filmIf you go to the cinema to appreciate the depths of humankind the\n",
      "feelings of real people to explore the characteriology of personalities if you go to the cinema to\n",
      "absorb magnificent photography be sure to put this film very high on your list preferably in first\n",
      "place The experience is profoundly rewarding causing the intelligent viewer to make diverse\n",
      "reflexions over the meaning of life itself With Mar Adentro Alejandro Amenábar has surpassed the\n",
      "best he has done to date and even redeemed certain deviations in his earlier films which smacked a\n",
      "little of being aimed at Hollywood This is not the case with this visual poem put to music Hollywood\n",
      "could never get anywhere near the effect of this tinglingly inspired human and humane storyIn no way\n",
      "should one interpret Mar Adentro as an apologia for euthanasia this story based on the real life of\n",
      "the Galician fisherman Ramón Sampedro is a cry from the bottom of the heart for life and love a\n",
      "reaching out for human compassion for understanding emotions Sampedro was an articulate and\n",
      "intelligent man who after a diving accident off the rocks of the Galician coast as a young man was\n",
      "condemned to live the next 27 years in bed Condenado a vivir 2001 TV was the first version of this\n",
      "mans life on which I have already commented However Amenábar has succeeded remarkably at portraying\n",
      "this man with his permanent enigmatic smile and witty sense of humour in an equally articulate and\n",
      "intelligent wayAnd Javier Bardem rose to the occasion met the challenge headon complete with a\n",
      "Galician accent producing an electrifying compelling enthralling performance such that the actor and\n",
      "the fisherman become fused into being the same person on screen Here indeed is an occasion to doff\n",
      "your cap and softly mutter chapeau Bardem is driven on in his task by a magnificent cast especially\n",
      "Belén Rueda Lola Due ⁇ as Mabel Rivera Celso Bugallo Los Lunes al Sol qv and Clara Segura Galician\n",
      "and Catalan accents taking prominent part Amenábar produces wonderful dialogues as these six rotate\n",
      "among themselves oneonone or in\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: Firstly let me make it clear that I love aircraft and usually any film with them in is worth\n",
      "watching and Ive sat through some shocking ones However the same is not true of this film James\n",
      "Stewart is an excellent actor but he is wasted in this Strategic Air Command promotional film The\n",
      "acting is mediocre and the direction is weak I had to stop watching this awful rubbish about half\n",
      "way through This was despite some really good maybe even the best aerial photography The trouble is\n",
      "even for an aviation nut like me making something out of the shocking aircraft featured B36 and B47\n",
      "just grates on the nerves too much Its a shame that the film wasnt made when the B52 appeared then\n",
      "the superlatives used for the aircraft in this film would have been valid Then I might have been\n",
      "able to sit through it Perhaps Im missing the point of the film which may be the angst suffered by\n",
      "loved ones while their beloved are on active duties In any case it could have been done much better\n",
      "Recommendation Well worth missing\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Its wartime drama WWII with French and Jews and Germans but this one is somehow fun\n",
      "earnestly so Director JeanPaul Rappeneau cowrote the script to his wellreceived film Bon Voyage 2003\n",
      "Unlike director Bertrand Taverniers Safe Conduct aka Laissezpasser 2002 wd Rolf Schubels Gloomy\n",
      "Sunday 1999 or wd Claude Berris Lucie Aubrac 1997 Bon Voyage is as chipper as its title sounds cest\n",
      "la vie whatever and we have the beautiful talented Isabelle Adjani to thank for It is her delightful\n",
      "performance throughout as the center of attraction and attention the cause and effect of it all that\n",
      "made the film so enjoyable as it is Hell whats another derailment of her plan and expectations will\n",
      "worry about that another time The backbone of the story does revolve around a pair of young\n",
      "enthusiasts Grégori Derangère as Frédéric and Virginie Ledoyen from Francois Ozons 8 Women as\n",
      "Camille The incomparable Gérard Depardieu the witty Yvan Attal of My Wife is An Actress and\n",
      "versatile Peter Coyote juggling French English and German here are some of the stellar cast involved\n",
      "There are many characters coming and going in this plot of a movie and how its all juggled is a\n",
      "skilful knack that requires no analysis Rappeneau is simply a genius The story just builds upon\n",
      "itself one episode after another or even with overlapping events but never confusing thats the\n",
      "delight of it all somehow every detail turns out right on the screen and we just lap it all up like\n",
      "a tastily presented French dessert literally so Theres thrills trills tender hesitant moments and\n",
      "taut ominous escapes all playing out in front of our eyes From reading the Directors Note on the\n",
      "Sony Pictures Classics Bon Voyage official site Rappeneau indicated this is his most personal and\n",
      "successful work ever Depicting Bordeaux 1940 from memories of his childhood years is very much close\n",
      "to his heart and he had worked and reworked the script for almost 3 years This film is a labor of\n",
      "love all round the cast and crew complementing the directors passion and a formidable script by\n",
      "collaborative writers along with the director and his son Julien adaptation efforts by Gilles\n",
      "Marchand Patrick Modiano and Jérôme TonnerreMusic\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: I had borrowed the three Sarah movies from a friend and had watched them while sick in bed\n",
      "during one weekend I thoroughly enjoyed every one of them I enjoyed how the last movie gave a\n",
      "glimpse of what Caleb and his sister were like when they grew up In addition I liked the\n",
      "carrythrough of the Billyboy song that first was heard during the credits of the first movie the\n",
      "title Sarah Plain and Tall However the one thing in Winters End that I didnt like was the youngest\n",
      "daughter She was a very cute little girl but she just had too much spirit and looked like a brat\n",
      "compared to the other kids even compared to talkative but still goodnatured Caleb when he was\n",
      "younger\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: This is an excellent documentary about Amália Rodrigues I enjoyed it very much its very well\n",
      "put together and very informative If you want to know who is Amália Rodrigues I highly recommend you\n",
      "see this film The Art Of Amália Rodrigues\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: 80s comedies especially ones with John Cusak are awesome Almost all are hillarious and\n",
      "instant classics and this film is no exception Plenty of nods to other films ie Godzilla and Jaws\n",
      "through out the movie that are so hillarious youll be laughing for hours Some may complain that the\n",
      "movie is a little corny at times but hey it was the 80s and things were always a little cheesy Throw\n",
      "in a young Demi Moore and an even louder Bob Cat and you have a laughfest on your fans If you havent\n",
      "seen this you better soon\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: There are some great Canadian films There are some crappy ones Last night I watched one of\n",
      "the crappy ones It wasnt the typical Canadian film where it tried to be so different by being arty\n",
      "This film tried to be some type of Hollywood gangster movie It was terribleFrom the beginning I had\n",
      "a sense that it would be a bad movie It had some of the cheesiest dialouge a movie can have There\n",
      "was this voice over for one scene and then it never returned That always bugs me when filmmakers\n",
      "just use voice over when they cant think of another creative way to tell a storyI know being in the\n",
      "Canadian film industry I should support my fellow brothers but this movie is junk The premise is\n",
      "something like a Sopranos episode only not realistic Some bankers mafia boss dad is on his death bed\n",
      "and orders the son to make the business legit Not so original And the workers complain about it but\n",
      "they just take the fact that they will soon be out of jobs like nothing To make it legit they use\n",
      "extortion Irony But not the good kind Then some freak show girl who had an awful Elvis wig and\n",
      "birthmark that covered half of her face robs the main character and kinda rapes him Anyways this guy\n",
      "for whatever reason now likes to dress up as girls Then this banker hooks up with a hooker when he\n",
      "has a beautiful future wife at home But he falls for the hooker because the hooker dresses like a\n",
      "man and puts makeup on him She blackmails him with some photos of him wearing bra and panties Yet he\n",
      "still loves her He also has no reason to leave his fiancé but he does in order to be with the\n",
      "hookerFor a movie about organize crime and sexual fetish there was neither action nor sex It was\n",
      "like a late night Cinemax porn movie without the good stuff The wouldbe sex scenes werent hot or\n",
      "sexy It was all too amateurish The movie had nothing going for it just the lame plotI dont think it\n",
      "was the actors fault I think they had a terrible script to work with What stuck out the most was the\n",
      "ridiculous characters The bad guys name was Uncle Bunny or something But the name wasnt important It\n",
      "was they all were cliché The dialouge was laughable throughout the movie and fellow moviegoers\n",
      "laughed al\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: This cheapo exploitation flick is some genuinely insipid stuff courtesy of spaghetti land\n",
      "director Lamberto Bava who wisely left his name off this junkThe basic crux of this outing concerns\n",
      "the discovery of some brutally mutilated individuals being washedup on shore in the Caribbean\n",
      "Authorities initially believe them to be victims of shark attacks but as the investigation unravels\n",
      "turns out to be something much more sinisterAll of this ultimately amounts to very little however we\n",
      "have here poor dubbing complimented by similarly weak script which often consists of nonsensical\n",
      "jabbering and is really of little consequence for the most part Acting can only be described as\n",
      "subpar which is par for the course in this instance Truly lax direction doesnt help things\n",
      "eitherSpecial effect mainly is for numerous closeups of various gory bodies missing limbs and so\n",
      "forth Of course there is the obligatory creature which periodically emerges at feeding time which\n",
      "looks something like a big monster octopus thing where its animation only consists of its pointed\n",
      "teeth ascending and descending in rhythmic articulation Overall the end result is none too\n",
      "convincing sure but admittedly is almost entertaining in a cheesy kind of fashionIt seems what the\n",
      "film makers were going for was a sort of lowrent hybrid of Jaws and Piranha but the final product is\n",
      "just a bloody shambles much like the corpses incessantly shown throughout this picture I find it\n",
      "difficult to think of any redeeming attributes to warrant viewing this so moreover strictly for\n",
      "incurable monster movie addicts\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Despite having an absolutely horrid script more about that later this film is still vaguely\n",
      "watchable just because it stars two excellent actors Barbara Stanwyck and Henry Fonda Aside from one\n",
      "or two REAL stinkers Id probably watch just about anything with them in the film as I am a huge fan\n",
      "of Hollywoods golden age of the 1930s and 40s However no matter how much I love their films I just\n",
      "cant recommend this filmThe movie begins with Fonda and Stanwyck on vacation at some ski resort The\n",
      "two havent yet met but the film begins loudly and obnoxiously with a scene in which Fonda horribly\n",
      "yodels while skiing It was done so unsubtly and made my teeth grind but I stuck it outespecially\n",
      "when Fonda fell into a snow bank and this stopped the yodeling In hindsight perhaps I should have\n",
      "just turned it off then Fonda is knocked out in the fall and Barbara goes for help Back at the ski\n",
      "lodge he seems okay but fortunately she is ALSO a doctor and has him xrayed and nurses him back to\n",
      "health He in turn becomes infatuated with her and proposes to her Despite hardly knowing each other\n",
      "they marry and so far the film seems like a sweet but very slight romantic comedyOnce home however\n",
      "all isnt rosy as she jumps right back into her job as a family doctor and he begins exhibiting signs\n",
      "that he is a controlling and potentially dangerous man due to his jealousy The film plays it all for\n",
      "laughs but frankly Fondas behaviors were really creepyspying on her and her male patients attacking\n",
      "or threatening ANY man she treats tripping a patient who already has a back injury and stomping into\n",
      "a surprise party and insisting that everyone there men and women are out to steal away his wife He\n",
      "comes off as a combination of a sociopath and paranoid schizophrenic but its all supposed to be for\n",
      "laughs Considering that he seems like a dangerous nut you would think that Stanwyck would file for\n",
      "an annulment along with a restraining order But oddly she gets mad but just cant stay mad at Fonda\n",
      "because hes so I cant think of the right wordcreepy is all that comes to mind\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: I really like this movie I like it not just because its a great early 80s movie with a GREAT\n",
      "soundtrack but I found that it has some thoughtprovoking moments They are just moments not the\n",
      "entire film Its definitely not like Less than ZeroThe scenes deal with typical peer pressure and\n",
      "also with more difficult problems like the betrayal of trust These problems are not easily resolved\n",
      "or forgotten by the characters Certain scenes will stand out and invite reflection on ones own\n",
      "teenage experiences and how those experiences may have affected ones character and outlook as an\n",
      "adultYou can watch this movie and think about the problems young adults must face and about your own\n",
      "experiences Or you can just pay attention to the boys quest to devirginize themselves Either way its\n",
      "a good movie\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: So Udo Kier earned like nine bucks and free food for this so that is a victory in and of\n",
      "itself More importantly this movie tells a very interesting tale about a group of salvage guys\n",
      "coming across the broken down Demeter I should warn you im gunna bounce around through this review\n",
      "real quick so buckle up First things first Coolio plays a guy named 187 187 likes drugs 187 finds a\n",
      "bunch of caskets on board and now i dont know anything about the future but maybe they smuggle drugs\n",
      "in caskets Not gunna say that was the craziest thing in this movie Later on the vampire gets out of\n",
      "his mist filled coffin and then the real hilarity begins First although this movie has the word\n",
      "Dracula in it he is actually not in this movie I have a theory though Out of the blue you see the\n",
      "salvage crews ship leave without them My theory is that Dracula was on board with his retarded\n",
      "brother Orlock Dracula told Orlock hell be right back Dracula got the hell out of this movie before\n",
      "he could be seen leaving Orlock to play the vampire for the six or so minutes he is in the movie The\n",
      "best part of this film and for those of you that have seen this you know what im gunna say is after\n",
      "187 gets sired embraced whatever He has this huge monologue about ejaculating on various parts of\n",
      "erika Elaniaks body and other super cool stuff Coolio seriously you are the best thing EVER Some\n",
      "other stuff happens in this movie too Like Casper Van Dean gets some work Orlock screams a lot and\n",
      "loses his arm and then we kinda lose track of him FOR THE REST OF THE MOVIE And thank god really We\n",
      "find out Erikas character is a police bot As the movie comes to a close we find out that the ship is\n",
      "on a course to ram into the sun The police bot and one other surviving character are doomed Rather\n",
      "then avoid certain death Erikas police bot reveals shes also a whore bot and they decide to screw\n",
      "each other and die Before they die in the sun they die for no reason yep thats right their ship\n",
      "blows up for no real reason This movie got the amazing rating for one reason Coolio My god if they\n",
      "gave\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: The problem with this and with all Vietnam War films is that theyre all too biased Antiwar\n",
      "films overlook the fact that the vast majority of US soldiers were heroes while prowar films\n",
      "overlook the fact that a lot of the soldiers did indeed commit atrocities like the one in this movie\n",
      "This film sucks Its time for a movie that is neither prowar nor antiwar nor liberal nor conservative\n",
      "but COMPLETELY UNBIASED\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Beautifulthat one word pretty much sums up this whole film Everything from the\n",
      "cinematography the directing the actingbrilliant At any point of the film you can pause it and you\n",
      "will no doubt be looking at something mosaic or artsy fartsy as some people would say I assure you\n",
      "that after one viewing Bobbycrush will be stuck in your head I know this from first hand experience\n",
      "Even the soundtrack is great It goes together very well with the tone and pace of the film Be\n",
      "thankful that Cam Archer exists in this world We need more people like him to make films that show\n",
      "love and shame in totally real and surreal imagery\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: This game requires stealth smart and a steady hand The gameplay is simply the best on top of\n",
      "that though are the interesting extras bullet holes stay in the walls enemies react to specific\n",
      "points where they have been hit by bullets there are tons of motion captured animations that make\n",
      "the enemies seem very real for instance when looking through a window at a guard he will stand there\n",
      "swatting flies away sneezing or scratching himself the list goes on This is the best licensedmovie\n",
      "conversion ever and it puts you in the shoes of the suavest super spy This game is the best reason\n",
      "for owning an N64\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: What a waste John Travolta and Scarlett Johansen deserved better than this To start at the\n",
      "beginning JT was horribly miscast in the lead here The role called for someone who could convince as\n",
      "a brokendown antihero someone who could look haunted and defeated Billy Bob Thornton would have fit\n",
      "the bill or even Al Pacino but JT is just too alive and looks to be having too much fun Also surely\n",
      "someone who has been through the mill to the extent JTs character had would have suffered some\n",
      "physical effects The character presented to the audience looked as if he could start as tight end\n",
      "for the Oakland Raiders Scarlett faired little better rolewise Where was the pain and conflict of\n",
      "what should surely have been troubling development And as for the plot well none of it makes sense\n",
      "The characters leap from one frame of mind to another seemingly without cause and certainly without\n",
      "explanation The pace of the film also leaves something to be desired namely pace This is a very slow\n",
      "film not that I have anything against slow films as long as they are heading somewhere The pace only\n",
      "picks up towards the very end when it shifts from a slow dirge to a frantic race to pack in as many\n",
      "tired clichés as possible In this it succeeds the only thing missing being something involving a\n",
      "small dog 3 out of 10 for this one purely for Gabriel Machts performance he was the only member of\n",
      "the cast who was a well cast and b able to convince in his role All in all a terrible disappointment\n",
      "and a real waste of a couple of hours\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: I always felt that Ms Merkerson had never gotten a role fitting her skills Familiar to\n",
      "millions as the Lt on Law and Order she has been seen in a number of theatrical releases always in a\n",
      "supporting role HBOs Lackawanna Blues changes that and allows this talented actress to shine as\n",
      "Nanny successful entrepreneur in a world changing from segregation to integration But the story is\n",
      "really about the colorful array of characters that she and her adopted son meet in a boarding house\n",
      "in Lackawanna New York a suburb of BuffaloThe story could be set in any major AfricanAmerican\n",
      "community of the 50s and 60s from Atlantas Sweet Auburn to New Yorks Harlem But the\n",
      "segregationintegration angle is only a subtle undercurrent in the colorful lives of the folks at\n",
      "Nannys boarding house The story revolves around Nannys relationships with all kinds of people played\n",
      "by some of the best actors in the business I purposely did not say black actorsthis ensemble is a\n",
      "stunning array of talent who happen to be black except for Jimmy Smits of course I recommend this\n",
      "film as a fun and colorful look at a bygone day\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: What Alice Found was a pleasant discovery As written and directed by A Dean Bell this is\n",
      "combination of a road movie with a cautionary tale as well as a voyage of discoveryIf you havent\n",
      "seen the film maybe you should stop reading hereAlice is a case study of a young woman that wants to\n",
      "break away from the unhappy life she leads in a New England town Her pretext for leaving is going to\n",
      "join her best friend who is away studying at a Miami university Alice is the product of a single\n",
      "mothers home one that is struggling to make ends meet in sharp contrast with the life of ease her\n",
      "friend seems to inhabit In flashbacks we get to see Alices life before going on the roadAlice like\n",
      "her namesake in Alice in Wonderland embarks in a trip to the unknown that life hasnt prepared her\n",
      "for The highways of America are full of predators in search of the weak and innocent Alice meets\n",
      "with disaster when her car breaks down the road and a friendly Southern couple come to her\n",
      "assistance when a strange man approaches in the darkness with the excuse he wants to help her Sandra\n",
      "and Bill convince her to come along in their plush RV on her way down SouthNothing has prepared\n",
      "Alice for what this couple turns out to be After all in her sheltered life she hasnt dealt with what\n",
      "Sandra and Bill her new benefactors do during the overnight stays at the rest stops in the American\n",
      "highways It comes as a shock to her the realization that the kind Sandra is nothing but a prostitute\n",
      "that plies her trade among the truck driving populace one meets in those placesAlice brilliantly\n",
      "played by Emily Grace is a study in how the young woman awakens to the new reality she cant escape\n",
      "In fact Sandra makes it seem so easy that Alice tries her luck at the oldest profession on earth in\n",
      "order to raise some badly needed moneyJudith Ivey gives a tremendous performance as Sandra Ms Ivey\n",
      "is perfect as the seemingly normal woman one wouldnt suspect she is doing the nasty with clients she\n",
      "and Bill find along the route they travel Ms Ivey is amazing when she reveals the truth about her\n",
      "life to an accusing Alice As the husband Bill Raymond is good in his portrayal as the husband that\n",
      "in reality is a procurerUnder the excellent direction of Mr Dean Bell the film is not afraid to go\n",
      "to places mainstream films dare not to go Congratulations\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: The Quick and the Undead is finally the first movie to actually render its own storyline\n",
      "null and void It is essentially one gigantic plot holeAside from that the acting was quite bad\n",
      "character motivations nonexistent or unbelievable and there wasnt a single character worth hanging\n",
      "our hat on The most interesting cast member who had great potential to be a dark horse protagonist\n",
      "got snuffed halfway through the proceedingsWhat the Quick and the Undead DOES serve as is an\n",
      "excellent example of how to do good colortiming It looked excellent when you take into account\n",
      "budget considerationsUnfortunately it plays out like a guy got his hands on a hundred grand and\n",
      "watched a few westerns most notably The Good The Bad and The Ugly and then just threw a bunch of\n",
      "elements haphazardly into a movie you know they have movies where characters do THIS Does it fit\n",
      "here No but who cares They do it in other movies so I should do it here Maybe a good view for\n",
      "burgeoning cinematographers and colorists firstyear filmschoolers Otherwise a mustmiss\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Did you ever watch a really bad movie and get mad about it Even a movie you didnt have high\n",
      "expectations for Well I just rented the movie Dead Line This is the US video title for Interferencia\n",
      "Now I have seen a lot of bad movies and watched a lot of B titles but this is in another league all\n",
      "its own It was put out on The Asylum label and anyone that rents a lot of direct to video horror\n",
      "films knows this label When you rent one of theres you know what your getting A lot of marginal\n",
      "acting low budget horror but usually still pretty good Not this one The acting by the three leads\n",
      "was beyond bad Even fast forwarding couldnt help The tag line on the front of the box saysin the\n",
      "tradition of DePalmas Body Double The nerve to compare this to that classic movie The only true\n",
      "comment is The screams you will hear are real Yea you will be the one screaming if you rent this\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Talk about your classics Ernie Fossilus the Foss from here on out came up with a cute and\n",
      "creative trailer totally spoofing Star Wars This gem is so jammed packed with tributes and gags I\n",
      "laugh every time Not only that when Star Wars did a reissue with new special effects Hardware Wars\n",
      "did the same Talk about a spoof that just wont die Theres a reason George Lucas calls this his\n",
      "favorite parody He was so impressed he even hired the Foss to work on Return of the Jedi Dont\n",
      "believe me check his entry in IMDbThis has to be the first and in my opinion the best parody ever\n",
      "done I think the Special Edition was a bit overdone but on reflection I think its PERFECT for the\n",
      "modern day rerelease of Star Wars and goes to prove that sometimes its wrong to mess with\n",
      "perfectionYes its only 10 minutes but its well worth your timeYoull laugh youll cry youll kiss $3\n",
      "goodbye Well maybe 15 for the DVD but youll be real happy you did\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: Crossfire remains one of the best Hollywood message movies because unlike the admirably\n",
      "intentioned Gentlemans Agreement which it beat to theatres by a few months it chooses to send its\n",
      "message via the form an excellent noir thriller rather than have an outraged star constantly saying\n",
      "Its because Im Jewish isnt it Its much easier to get the message that hate is like a loaded gun\n",
      "across when the dead bodies are actual rather than metaphorical Somewhat shamefully the brief\n",
      "featurette on the Warners DVD doesnt mention that novelist Richard Brooks disowned the film over the\n",
      "shift from a homophobic murder to an antiSemitic one but its interesting to note that while the\n",
      "victim is killed primarily because he is Jewish theres little doubt in Sam Levenes performance that\n",
      "the character is in fact also gay  ⁇  not a mincing caricature but theres definitely a two lost\n",
      "souls aspect to his scenes with George Coopers confused soldier Theres not much of a mystery to who\n",
      "the murderer is even though the killing is carried out in classic noir shadows the body language of\n",
      "the killer is instantly recognisable but then the film has its characters drift to the same\n",
      "conclusion before the halfway point the tension comes from proving it and saving the fall guyTheres\n",
      "an element of Ealing Films to the gang of soldiers teaming together to get their buddy out of a fix\n",
      "you could almost see that aspect as a blueprint for Hue and Cry but the atmosphere is pure RKO noir\n",
      "Set over one long sweltering night the film has a great look filled with deep dark blacks and\n",
      "shadows born as much out of economy as style it cut back on lighting time and allowed director\n",
      "Edward Dmytryk more time to work with the actors and the excellent cast make the most of the fine\n",
      "script a laidback but quietly charismatic Robert Mitchum Robert Youngs Maigretlike detective Gloria\n",
      "Grahames tramp and the perpetually creepy Paul Kelly as her compulsive liar admirer a guy who tries\n",
      "on stories the way other people try on ties But the lasting impression is of Robert Ryans excellent\n",
      "performance as a guy who could do with a good leaving alone as he does his best to help the wrongly\n",
      "accused man all the way to death row A big surprise hit in 1946 as a reward Dmytryk and producer\n",
      "Adrian Scott\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: Symbolism galore great tunes this film crushed their soon to be no more target audiences\n",
      "expectations These monkees and the naturally selected members of the group were witnessing a subtle\n",
      "yet in your face kiss goodbye to each other The message rings true today the cage you escape from\n",
      "and the bridge you want to jump off of are the next generations own disappointments there will\n",
      "always be new kids on the block replacing those who break free from the chains The film can be\n",
      "frustrating at times because the themes the film attacks are so blatantly apart of the American way\n",
      "of life a thinking and reasoning person cannot help but stare at their own reflection in the scenes\n",
      "of Head and question not only their personal motives for continuing the madness of everyday American\n",
      "life but the motives of those who want it to continue for the sake of madness The final scene\n",
      "similar to Don Quixotes chivalric daring of the caged tiger to exit for battle represents just how\n",
      "delusional and impossible most dreams are\n",
      "\n",
      "Actual sentiment: positive\n",
      "Predicted sentiment: positive\n",
      "=====================================================================\n",
      "\n",
      "Review: 1 thing this movie sucks BIG TIMEi was into singaporean comedy when Chiken Rice war came\n",
      "along But this time even Gurmit Singh welldone acting cant pull this one of A total failure of\n",
      "following HKs Shaolin Soccer Next time do ur own thing\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: Alexandra Maria Lara A very beautiful and enticing woman but not a good actress In all the\n",
      "films Ive seen her in she appears to me as the exact same character Whether it be in THE DOWNFALL\n",
      "NACKT VOM SUCHEN UND FINDEN DER LIEBE and now WO IST FRED She always is plays the young goodhearted\n",
      "woman who is a little naive and doesnt know how to handle the things happening to her She disposes\n",
      "of a repertoire of probably five different facial expressions that she works with abundantly I\n",
      "personally have a hard time believing that she could play a mysterious and slightly obnoxious\n",
      "character because it just isnt in here So shes typecast as the nice girl next door which she is but\n",
      "once again she aint up to snuff when it comes to acting Til Schweiger Same thing The film Downright\n",
      "stupid As it was an American movie it would have been a great role for Adam Sandler who I dont like\n",
      "either I wasnt offended by the fact that this is a film with handicapped people in it I just thought\n",
      "that the jokes resulting from this werent funny at all I chuckled twice or three times but when I\n",
      "was halfway through it I was just bored and annoyed and wanted this flick to end\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: This is one of Crichtons best books The characters of Karen Ross Peter Elliot Munro and Amy\n",
      "are beautifully developed and their interactions are exciting complex and fastpaced throughout this\n",
      "impressive novelAnd about 998 percent of that got lost in the film Seriously the screenplay AND the\n",
      "directing were horrendous and clearly done by people who could not fathom what was good about the\n",
      "novel I cant fault the actors because frankly they never had a chance to make this turkey live up to\n",
      "Crichtons original work I know good novels especially those with a science fiction edge are hard to\n",
      "bring to the screen in a way that lives up to the original But this may be the absolute worst\n",
      "disparity in quality between novel and screen adaptation ever The book is really really good The\n",
      "movie is just dreadful\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n",
      "Review: I was a fan of the AMERICAN WEREWOLF IN LONDON movie and so was curious whether a 16year\n",
      "later sequel could be done with French language and local recast major supporting and minor\n",
      "characters Tonight I watched the edited for FOX Network version that was some sort of curious hybrid\n",
      "of several hyperactive sequels The screenwriters and directors pay homage to certain of the key plot\n",
      "concepts Tourist gets wolf bite full moon comes out boy meets girl boy becomes beast boy dies heroic\n",
      "death after help from ghost victim For me the oddest aspect of this formula teen horror special\n",
      "effectride was the casting of the school teacherlove interest of the TV comedy ED as one of the\n",
      "werewolfs clueless victims who is more or less totally unsympathetic in the scripted lines they\n",
      "handed her I havent seen another horrorflick that this movie is sequelling a vampire fighting flick\n",
      "titled BLADE but I guess that parts of its plotline must explain how villain werewolves theyre\n",
      "spoofish are threatening the good werewolf pair during a long part of the movie There is also a\n",
      "final conflict in a Paris subway train a la SPEED This 1997 studio product is an odd hybrid of a\n",
      "film since considerable technical effects are shown for scary purposes but the authentic terrors of\n",
      "the original have been completely undermined in my opinion Such an odd rewrite of the werewolf\n",
      "legend and moviemythology My suggestion to those considering this at the video store go for a\n",
      "classic top of the line Thriller instead Alfred Hitchcocks PSYCHO\n",
      "\n",
      "Actual sentiment: negative\n",
      "Predicted sentiment: negative\n",
      "=====================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(32):\n",
    "    lines = textwrap.wrap(\"Review:\\n%s\\n\" % texts[i], width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual sentiment: %s\" % targets[i])\n",
    "    print(\"Predicted sentiment: %s\" % dec[i])\n",
    "    print(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N60XxjcpK8L9"
   },
   "source": [
    "# Now predict on all the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121,
     "referenced_widgets": [
      "eaa9970e82a846638206d992d653c493",
      "0a37d163cb6340eda137f4c3636d5050",
      "15519f13f40041ca9b02af935ea38ba4",
      "4933b5b74d0e48c4a253f483e3914d50",
      "83d3025c26b14142b123930bf88da7ac",
      "a72fc2caf4c94ca9be52b1c01adc2279",
      "46c04cfb7dec48ee8a8264ec64f218ae",
      "7c864810693c468eb6bb6099a6a4dc71"
     ]
    },
    "id": "mO7_r6mNKwVl",
    "outputId": "736225fd-6527-4633-de25-6df1acb2ca3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa9970e82a846638206d992d653c493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=782.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, num_workers=4)\n",
    "model.model.eval()\n",
    "outputs = []\n",
    "targets = []\n",
    "for batch in tqdm(loader):\n",
    "  outs = model.model.generate(input_ids=batch['source_ids'].cuda(), \n",
    "                              attention_mask=batch['source_mask'].cuda(), \n",
    "                              max_length=2)\n",
    "\n",
    "  dec = [tokenizer.decode(ids) for ids in outs]\n",
    "  target = [tokenizer.decode(ids) for ids in batch[\"target_ids\"]]\n",
    "  \n",
    "  outputs.extend(dec)\n",
    "  targets.extend(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "NpRLYF3UK9x0"
   },
   "outputs": [],
   "source": [
    "for i, out in enumerate(outputs):\n",
    "  if out not in ['positive', 'negative']:\n",
    "    print(i, 'detected invalid prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-JoEp6kVK90_",
    "outputId": "f36640c7-a2d9-46a8-90c9-d82adb77a58d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94776"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(targets, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70TdLG48K931",
    "outputId": "b2f84b6a-2ede-4314-8714-02752b002a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95     12500\n",
      "    positive       0.94      0.96      0.95     12500\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.95      0.95     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(targets, outputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_M_ShwELGap"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-3YnIYaLGdF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a37d163cb6340eda137f4c3636d5050": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e6b30da2d81465c8a5031cdfb9d34c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "119733b98e0c4cb6a22aa97143e35b09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af371d5453b743558cbccf3c250743c9",
      "placeholder": "​",
      "style": "IPY_MODEL_f4d302e039704a2ab2c35b61a90ceb24",
      "value": " 3125/3125 [1:33:11&lt;00:00,  1.79s/it, loss=0.004, v_num=0, val_loss=0.0759]"
     }
    },
    "14e3380b02234c57bcf28113d4465301": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15368d6fee634355b25bdda23c385b6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "15519f13f40041ca9b02af935ea38ba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a72fc2caf4c94ca9be52b1c01adc2279",
      "max": 782,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83d3025c26b14142b123930bf88da7ac",
      "value": 782
     }
    },
    "1b317b6e12a544d09a5e511989213ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a7912bca01f4b8899c1f8a720fcb8ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ceb41206ac34659b679cd69479097f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30def0feafdf4fb0b0608654816a6cc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "319c8bcbd5934059860c677f7ed24aad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35d72f1a32ae4c5ebe1b237bd9880099": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3733bf628ccb4901aaedeab4633bad2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3a6e988601574b95b4e4ba3f7d186fb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f0788856a524f0ea846eedf2395cd14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e26037505d8b4000a6dd7201e30c92d0",
       "IPY_MODEL_828b17739bc347f2b3f17c302fe29ecd"
      ],
      "layout": "IPY_MODEL_cd8ef8b38c994a1999462f9223207d37"
     }
    },
    "41db090906044995bab2cc114e8df429": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4324eea8cd4c4cfca445a502ad780ae5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "46c04cfb7dec48ee8a8264ec64f218ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49096c116ac74c2cabe7279b93671618": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4933b5b74d0e48c4a253f483e3914d50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c864810693c468eb6bb6099a6a4dc71",
      "placeholder": "​",
      "style": "IPY_MODEL_46c04cfb7dec48ee8a8264ec64f218ae",
      "value": " 782/782 [32:20&lt;00:00,  2.48s/it]"
     }
    },
    "4d847cae27924548b542c8cd027e8743": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c8899aec2144c0f85595ba30adb8cff",
      "placeholder": "​",
      "style": "IPY_MODEL_5c4c75c93ef34f899b89543893de421c",
      "value": " 5/5 [00:03&lt;00:00,  1.29it/s]"
     }
    },
    "4deb8e18764d449d925323457e999855": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cf47153db36941278f55f270eade36f0",
       "IPY_MODEL_119733b98e0c4cb6a22aa97143e35b09"
      ],
      "layout": "IPY_MODEL_cc0658a972514176a114d30390d97979"
     }
    },
    "59d70863485248b6b6e6bfd9c7312255": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b317b6e12a544d09a5e511989213ae8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41db090906044995bab2cc114e8df429",
      "value": 1
     }
    },
    "5c4c75c93ef34f899b89543893de421c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c8899aec2144c0f85595ba30adb8cff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6747d086529349158632278e67b2eda5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59d70863485248b6b6e6bfd9c7312255",
       "IPY_MODEL_e3ad19060d6e48528fbf91568e4e20b5"
      ],
      "layout": "IPY_MODEL_c1a9c72c12b2451ab400a7aba3b25135"
     }
    },
    "723194ef36e84be7bbdad7ef612db7f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e9bb4717bbc54bc78e3f865295954524",
       "IPY_MODEL_4d847cae27924548b542c8cd027e8743"
      ],
      "layout": "IPY_MODEL_4324eea8cd4c4cfca445a502ad780ae5"
     }
    },
    "744a6288f3af4526924d50ea99334796": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7f4620330cf4affac01d9b480128ae0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_15368d6fee634355b25bdda23c385b6f",
      "value": 1
     }
    },
    "7a4eaa255b0144dba417dcf5be147274": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c864810693c468eb6bb6099a6a4dc71": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "818a22c2de8643d6ba2d7280fc29ec92": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb774c80a71c40f6923477ff6f00fef6",
       "IPY_MODEL_bb4052d977284705983851c44cd1bfba"
      ],
      "layout": "IPY_MODEL_2a7912bca01f4b8899c1f8a720fcb8ad"
     }
    },
    "828b17739bc347f2b3f17c302fe29ecd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3d2f77978e94d468361da7056e4555c",
      "placeholder": "​",
      "style": "IPY_MODEL_3a6e988601574b95b4e4ba3f7d186fb4",
      "value": " 892M/892M [00:24&lt;00:00, 35.8MB/s]"
     }
    },
    "83d3025c26b14142b123930bf88da7ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8532abe29c7f46e0b157ae58089849bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9cad5d60d32a4689b754626a50ef2fb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_744a6288f3af4526924d50ea99334796",
       "IPY_MODEL_f3964ccfda154661810feca1129a2f87"
      ],
      "layout": "IPY_MODEL_a7c85a38e3504f42859620d583c80025"
     }
    },
    "a72fc2caf4c94ca9be52b1c01adc2279": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7c85a38e3504f42859620d583c80025": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "aebd30288b4044bab1b1a0f9f3a329bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "af371d5453b743558cbccf3c250743c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb4052d977284705983851c44cd1bfba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14e3380b02234c57bcf28113d4465301",
      "placeholder": "​",
      "style": "IPY_MODEL_d2bd31657157479daaaa7a7540a5a509",
      "value": " 1.20k/1.20k [00:25&lt;00:00, 46.4B/s]"
     }
    },
    "bd7c7b15af4640389d03a461e59ed67a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1a9c72c12b2451ab400a7aba3b25135": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "cc0658a972514176a114d30390d97979": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "cd8ef8b38c994a1999462f9223207d37": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf47153db36941278f55f270eade36f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Epoch 2: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_319c8bcbd5934059860c677f7ed24aad",
      "max": 3125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49096c116ac74c2cabe7279b93671618",
      "value": 3125
     }
    },
    "d2bd31657157479daaaa7a7540a5a509": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7f4620330cf4affac01d9b480128ae0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e26037505d8b4000a6dd7201e30c92d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f21d8dc9aa524e7f8a1c1191580ec695",
      "max": 891691430,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3733bf628ccb4901aaedeab4633bad2c",
      "value": 891691430
     }
    },
    "e3ad19060d6e48528fbf91568e4e20b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ceb41206ac34659b679cd69479097f2",
      "placeholder": "​",
      "style": "IPY_MODEL_8532abe29c7f46e0b157ae58089849bb",
      "value": " 250/250 [02:45&lt;00:00,  1.52it/s]"
     }
    },
    "e9bb4717bbc54bc78e3f865295954524": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validation sanity check: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd7c7b15af4640389d03a461e59ed67a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30def0feafdf4fb0b0608654816a6cc6",
      "value": 1
     }
    },
    "eaa9970e82a846638206d992d653c493": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15519f13f40041ca9b02af935ea38ba4",
       "IPY_MODEL_4933b5b74d0e48c4a253f483e3914d50"
      ],
      "layout": "IPY_MODEL_0a37d163cb6340eda137f4c3636d5050"
     }
    },
    "f21d8dc9aa524e7f8a1c1191580ec695": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3964ccfda154661810feca1129a2f87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a4eaa255b0144dba417dcf5be147274",
      "placeholder": "​",
      "style": "IPY_MODEL_35d72f1a32ae4c5ebe1b237bd9880099",
      "value": " 250/250 [02:44&lt;00:00,  1.52it/s]"
     }
    },
    "f3d2f77978e94d468361da7056e4555c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4d302e039704a2ab2c35b61a90ceb24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb774c80a71c40f6923477ff6f00fef6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e6b30da2d81465c8a5031cdfb9d34c1",
      "max": 1199,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aebd30288b4044bab1b1a0f9f3a329bd",
      "value": 1199
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
